******************************************Creating Database from Scratch using VsCode and postgresSQL pgAdmin***********************************************************
Steps:
1. Open pgAdmin postgresSQL
2. Open folder in VsCode and Make sure SQLTools and PostgresSQL/CockroachDriver extension is added
3. Click on SQLTools > Add new connection > PostgreSQL > (Connection name/ Database/Username) = postgres
4. Test connection > Enter Password > Save Connection

Note: Click postgres database > Now create your own database because we dont use the core database the is created by deafault.

5. Goto VsCode and click "Add new connection" > PostgresSQL > (connecion name/ database) = sql_dipesh > username = postgresSQL
6. Test connection > allow > password > save connection
7. Click sql_dipesh database > Click "New SQL File"

8. To Create .sql file (test.sql or create_database.sql) on the folder and create the database using below command
   CREATE DATABASE sql_dipesh;
9. Now you can see newly created database in pgAdmin if you refresh



6. Download the CSV file that you want to work with.
   Since we will be using job application csv dataset, you can download dataset from link below
   https://drive.google.com/drive/folders/1moeWYoUtUklJO6NJdWo9OV8zWjRn0rjN
7. Now we Create our SQL table with proper columns where will copy data from CSV file to newly created SQL table
   Create new file create_tables.sql and write following commands
-- Create company_dim table with primary key
CREATE TABLE public.company_dim
(
    company_id INT PRIMARY KEY,
    name TEXT,
    link TEXT,
    link_google TEXT,
    thumbnail TEXT
);

-- Create skills_dim table with primary key
CREATE TABLE public.skills_dim
(
    skill_id INT PRIMARY KEY,
    skills TEXT,
    type TEXT
);

-- Create job_postings_fact table with primary key
CREATE TABLE public.job_postings_fact
(
    job_id INT PRIMARY KEY,
    company_id INT,
    job_title_short VARCHAR(255),
    job_title TEXT,
    job_location TEXT,
    job_via TEXT,
    job_schedule_type TEXT,
    job_work_from_home BOOLEAN,
    search_location TEXT,
    job_posted_date TIMESTAMP,
    job_no_degree_mention BOOLEAN,
    job_health_insurance BOOLEAN,
    job_country TEXT,
    salary_rate TEXT,
    salary_year_avg NUMERIC,
    salary_hour_avg NUMERIC,
    FOREIGN KEY (company_id) REFERENCES public.company_dim (company_id)
);

-- Create skills_job_dim table with a composite primary key and foreign keys
CREATE TABLE public.skills_job_dim
(
    job_id INT,
    skill_id INT,
    PRIMARY KEY (job_id, skill_id),
    FOREIGN KEY (job_id) REFERENCES public.job_postings_fact (job_id),
    FOREIGN KEY (skill_id) REFERENCES public.skills_dim (skill_id)
);

-- Set ownership of the tables to the postgres user
ALTER TABLE public.company_dim OWNER to postgres;
ALTER TABLE public.skills_dim OWNER to postgres;
ALTER TABLE public.job_postings_fact OWNER to postgres;
ALTER TABLE public.skills_job_dim OWNER to postgres;

-- Create indexes on foreign key columns for better performance
CREATE INDEX idx_company_id ON public.job_postings_fact (company_id);
CREATE INDEX idx_skill_id ON public.skills_job_dim (skill_id);
CREATE INDEX idx_job_id ON public.skills_job_dim (job_id);

8. Now lets copy our data from CSV files we downloaded into our SQL tables respectively
   Create new folder "Temp" in Local Disk C > Paste the CSV files > Copy the path and use it in below commands
   Create copy_data.sql and write below command
COPY company_dim
FROM 'C:\Temp\company_dim.csv'
WITH (FORMAT csv, HEADER true, DELIMITER ',', ENCODING 'UTF8');

COPY skills_dim
FROM 'C:\Temp\skills_dim.csv'
WITH (FORMAT csv, HEADER true, DELIMITER ',', ENCODING 'UTF8');

COPY job_postings_fact
FROM 'C:\Temp\job_postings_fact.csv'
WITH (FORMAT csv, HEADER true, DELIMITER ',', ENCODING 'UTF8');

COPY skills_job_dim
FROM 'C:\Temp\skills_job_dim.csv'
WITH (FORMAT csv, HEADER true, DELIMITER ',', ENCODING 'UTF8');

9. Now you can check if the data are filled in or not
SELECT *
FROM job_postings_fact
LIMIT 100;
